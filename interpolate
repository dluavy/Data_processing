import datetime
import functools
from multiprocessing import Pool
import numpy as np
import os
import pandas as pd
import sys
import traceback
import warnings

from cluster_utils.io import makedirs_safely
import db_queries
from gbd import constants as gbd
from gbd.estimation_years import estimation_years_from_gbd_round_id
from gbd.gbd_round import gbd_round_from_gbd_round_id, validate_gbd_round_id
from gbd_artifacts.exposure import ExposureMetadata
from gbd_artifacts.modelable_entity import ModelableEntityMetadata
from get_draws.api import get_draws
from get_draws.base.exceptions import EmptyDataFrameException
from test_support.profile_support import profile

from chronos.exceptions import IllegalArgumentError
from chronos.expansion import interpolate as interp
from chronos.expansion import (extrapolate,
                               VALID_EXTRAPOLATION_MEASURES,
                               VALID_EXTRAPOLATION_SOURCES)
from chronos.utils import (
    concat,
    resolve_all_locs,
    standardize_all_from_raw_arg,
    validate_decomp_input
)


# Module constants
VALID_FIELDS = ['cause_id', 'modelable_entity_id', 'rei_id', 'sequela_id']
VALID_SOURCES = [
    'epi',
    'codem',
    'dalynator',
    'como',
    'burdenator',
    'sev',
    'codcorrect',
    'exposure',
    'exposure_sd',
    'tmrel',
    'paf'
]
SOURCES_WITHOUT_MEASURE = ['exposure']


def _safe_draw_call(gbd_id_type, gbd_id, measure_id, location_id, age_group_id,
                    sex_id, year_id, status, version_id, decomp_step,
                    gbd_round_id, source, downsample):
    if gbd_round_id == 3:
        call_measure = None
    else:
        call_measure = measure_id

    df = get_draws(gbd_id_type,
                   gbd_id,
                   source,
                   measure_id=call_measure,
                   location_id=location_id,
                   year_id=year_id,
                   age_group_id=age_group_id,
                   sex_id=sex_id,
                   status=status,
                   version_id=version_id,
                   decomp_step=decomp_step,
                   gbd_round_id=gbd_round_id,
                   downsample=downsample)
    draw_cols = [col for col in df.columns if 'draw_' in col]
    id_cols = list(set(df.columns) - (set(draw_cols + ['year_id'])))
    if 'parameter' in id_cols:
        cats = df['parameter'].unique().tolist()
        df['parameter'] = pd.Categorical(
            df['parameter'], categories=cats, ordered=True)
    if 'modelable_entity_id' in id_cols:
        df['modelable_entity_id'].fillna(-1, inplace=True)
    return df


@profile
def _interp_helper(gbd_id_type, gbd_id, measure_id, age_group_id, sex_id,
                   year_id, status, version_id, decomp_step, gbd_round_id,
                   source, downsample, interp_method, location_id):

    try:
        df = _safe_draw_call(gbd_id_type, gbd_id, measure_id, location_id,
                             age_group_id, sex_id, year_id, status, version_id,
                             decomp_step, gbd_round_id, source, downsample)

        return interp(df, gbd_id=gbd_id, gbd_id_type=gbd_id_type,
                      measure_id=measure_id, location_id=location_id,
                      age_group_id=age_group_id, sex_id=sex_id,
                      year_start_id=min(year_id), year_end_id=max(year_id),
                      interp_method=interp_method)
    except EmptyDataFrameException:
        return int(location_id)
    except Exception:
        tb = "\n\t".join(("".join(traceback.format_exception(
            *sys.exc_info()))).split("\n"))
        return tb


@profile
def _get_mean_values(source, gbd_id, measure_id, age_group_id, gbd_round_id,
                     decomp_step):
    # we will extrapolate using linear regresion if we have a dismod model or
    # risk exposure model and we have at least one measure in the list of
    # approved measures for extrapolation. In that case we need to get the
    # means of the dismod/exposure model. In any other case, return None.
    possible_extrap_source = source in VALID_EXTRAPOLATION_SOURCES
    possible_extrap_measure = [m for m in VALID_EXTRAPOLATION_MEASURES
                               if m == measure_id]

    if not (possible_extrap_source and possible_extrap_measure):
        return None

    # use loc set 35 (gbd modeling) to get df of means
    location_set_id = 35
    gbd_team = 'epi'
    # TODO: allow retrieval of means that aren't best?
    if source == 'exposure':
        # need to get exposure MEs associated with risk
        meta = ExposureMetadata(gbd_id, gbd_round_id=gbd_round_id,
                                decomp_step=decomp_step)
    elif source == 'epi':
        meta = ModelableEntityMetadata(gbd_id, gbd_round_id=gbd_round_id,
                                       decomp_step=decomp_step)
    MVs = np.atleast_1d(meta.best_version).tolist()

    mean_df = concat(
        [db_queries.get_model_results(
            gbd_team, gbd_id=gbd_id, age_group_id=age_group_id,
            model_version_id=mv, measure_id=measure_id,
            year_id=db_queries.get_demographics(
                gbd_team, gbd_round_id=gbd_round_id)['year_id'],
            location_set_id=location_set_id, gbd_round_id=gbd_round_id,
            decomp_step=decomp_step)
            for mv in MVs])
    if mean_df.empty:
        raise RuntimeError("No means found for model version {}".format(MVs))
    return mean_df


def validate_year_args(reporting_year_start, reporting_year_end, gbd_round_id):
    # Validate the start_year and end_year arguments
    valid_years = [1980] + [int(year) for year in
                            estimation_years_from_gbd_round_id(gbd_round_id)]

    # valid start years include all estimation years except the terminal
    # estimation year.
    if reporting_year_start not in valid_years[:-1]:
        raise IllegalArgumentError(
            "Invalid entry for reporting_year_start. Valid starting years are "
            "{}".format(", ".join(map(str, valid_years[:-1])))
        )

    # valid end years include all estimation years except the first estimation
    # year.
    if reporting_year_end not in valid_years[1:]:
        raise IllegalArgumentError(
            "Invalid entry for reporting_year_end. Valid ending years are "
            "{}".format(", ".join(map(str, valid_years[1:])))
        )
    # Check for invalid spans: start > end
    if reporting_year_start >= reporting_year_end:
        raise IllegalArgumentError(
            "The starting reporting year must be less than the end reporting "
            "year. Received start year: {start}, end year: {end}"
            .format(start=reporting_year_start, end=reporting_year_end)
        )


def validate_measure(measure_id, source):
    # some sources can't have measure_id passed to get_draws, so in those
    # cases, it's ok to not specify measure
    if (measure_id is not None) and (not isinstance(measure_id, int)):
        raise IllegalArgumentError(
          	f"Can only interpolate a single measure_id of type Int at a time. "
          	f"Received: {measure_id} of type {type(measure_id)}"
        )
    # If no measure_id is provided and source is not 'exposure', raise
    if measure_id:
        valid_measures = db_queries.get_ids('measure').measure_id.unique()
        if measure_id not in valid_measures:
            raise IllegalArgumentError(
                "Invalid entry for measure_id. Valid measure_ids are: {ids} "
                "Received {meas}."
                .format(ids=', '.join(map(str, valid_measures)),
                        meas=measure_id)
            )
    elif source not in SOURCES_WITHOUT_MEASURE:
        raise IllegalArgumentError(
            "All sources except for 'exposure' must call interpolate with only"
            " one measure_id at a time. Received: {meas}"
            .format(meas=measure_id)
        )


def validate_num_workers(num_workers):
    if not isinstance(num_workers, int) or num_workers < 1:
        raise IllegalArgumentError(
            "Num_workers must be an integer greater than or equal to 1. "
            "Received {num_workers}".format(num_workers=num_workers)
        )


def validate_gbd_args(gbd_id, gbd_id_type, source):
    if not isinstance(gbd_id, int):
        raise IllegalArgumentError(
          	f"Can only interpolate a single gbd_id of type Int at a time. "
          	f"Received: {gbd_id} of type {type(gbd_id)}"
        )
    if gbd_id_type not in VALID_FIELDS:
        raise IllegalArgumentError(
            "Invalid gbd_id_type passed. Received {type_id} Valid entries "
            "are {valid}.".format(
                type_id=gbd_id_type, valid=', '.join(map(str, VALID_FIELDS)))
        )
    if source not in VALID_SOURCES:
        raise IllegalArgumentError(
            "Invalid entry for source. Received {source}. "
            "Valid entries are {valid}"
            .format(source=source, valid=', '.join(map(str, VALID_SOURCES)))
        )


@profile
def interpolate(gbd_id_type,
                gbd_id,
                source,
                out_dir=None,
                measure_id=None,
                location_id='all',
                location_set_id=35,
                location_set_version_id=0,
                reporting_year_start=1990,
                reporting_year_end=None,
                age_group_id='all',
                sex_id='all',
                gbd_round_id=gbd.GBD_ROUND_ID,
                status='best',
                decomp_step=None,
                version_id=None,
                downsample=False,
                interp_method='pchip',
                num_workers=10):
    """
    Returns a dataframe of interpolated results for a given gbd_id_field/
    gbd_id for a given set of ages, locations, sexes, single measure, and
    status. If 'all' is an input, runs on all possible values of that argument.
    Accepts 'all' for ages, locations, and sexes. Must run interpolate on one
    gbd_id and one measure at a time, for memory's sake.

    Note:

    Measures 5, 6, 8, 15, and 19 coming out of dismod or risk will be
    back-extrapolated using linear regression, if user requests data back to
    1980. All other measures and sources will just have 1990 copied and added
    as the 1980's. For questions on this methodology talk to Caitlyn Steiner.

    Best practices:

    The 'pchip' (piece-wise cubic interpolating polynomial) method of
    interpolation (which is the default method) will produce different
    estimates based on the number of years of data passed in. This is because
    the slope of the curve passing through a given known data point is informed
    by the position of both of the points adjascent to it.  Therefore, it is
    considered best practice to supply data for as many of the gbd estimation
    years as you have access to (eg: reporting_year_start=1990,
    reporting_year_end=2017 for gbd_round 5) even if you are only trying to
    interpolate a small range (1990 to 1995 for example).

    If using the 'num_workers' argument to speed up computation over a large
    number of locations it is both recommended and conscientious to request at
    least as many threads as you have workers.  The default num_workers is 10,
    so 10 threads should be requested if using the default. If you are
    interpolating over a small dataset with few locations feel free to set
    num_workers=1, and in turn fthreads=1.

    Arguments:
        gbd_id_type (str): type of id to be queried,
            i.e. cause_id or modelable_entity_id
        gbd_id (int): id that correspond to the gbd_id_type,
            i.e. 294 for cause_id, or 1167 for modelable_entity_id
        out_dir: directory where you want to save interpolated draws.
            default None, which returns to memory instead of saving
        source (str): Which process do you want draws from?
            One of 'epi', 'codem', 'dalynator', 'como', 'burdenator',
            'codcorrect', 'exposure', 'exposure_sd', 'paf', or 'tmrel'.
            See get_draws documentation for descriptions of each source.
        measure_id (int): measure_id to be queried. Must call
            interpolate on one measure at a time.
        location_id (int or intlist, optional): locations to be queried.
            default all locations in the location_set
        location_set_id (int, optional): location set to be queried if
            querying all locations. default 'Model Results'
        location_set_version_id (int, optional): location set version to be
            queried if querying all locations. overwrites location_set_id
        reporting_year_start: the min you you want your interpolated draws
            output dataset to contain. Default 1990
        reporting_year_end: the max you you want your interpolated draws
            output dataset to contain. Default to last year of GBD round.
        age_group_id (int or intlist, optional): ages to be queried.
            default all most-detailed ages, 2-21, 30, 31, 32, 235
        sex_id (int or intlist, optional): sex to be queried.
            default all sexes
        gbd_round_id (int, optional): id of gbd round to be queried.
            defaults to current gbd round id
        status (str): Specifies which version of the estimates to be returned.
            Allowed values are 'best' or 'latest'.
        decomp_step (str): Specifies which decomposition step the returned
            estimates should be from. Default to None. If using interpolate for
            GBD round 6 and above, must specify one of 'step1', 'step2',
            'step3', 'step4', 'step5', or 'iterative'.
        version_id (int, optional): if specified, model_version to use;
            overwrites status.
        interp_method (str): Interpolation method to use. 'pchip' for
            a spline interpolation or 'linear' for linear interpolation.
        downsample (bool, False): If False, and draws contain multiple
            different n_draws counts (ie 1000 and 100), raise. If True,
            downsample 1000 to 100 and return a dataframe with 100 draws.
            See get_draws documentation for more details.
        num_workers (int, 10): Determines the number of workers in the
            worker pool. Has the potential to reduce run time if location_id
            is a long list. Best practice is to ask for as many threads
            as you will have workers.

    Returns:
        pd.Dataframe:
            location_id, year_id, age_group_id, sex_id, measure_id,
            cause_id/modelable_entity_id, model_version_id, draw_0-draw_999

    Raises:
        ValueError: If any locations, ages, years, or sexes or decomp_step are
            invalid.
        IllegalArgumentError: If any gbd_id_field, source, measure_id are
            invalid.
    """
    # Validate gbd_round_id and decomp_step
    validate_decomp_input(decomp_step, gbd_round_id)
    validate_gbd_round_id(gbd_round_id)

    # Validate all input args
    validate_gbd_args(gbd_id, gbd_id_type, source)
    validate_num_workers(num_workers)
    if not reporting_year_end:
        reporting_year_end = int(gbd_round_from_gbd_round_id(gbd_round_id))
    validate_year_args(reporting_year_start, reporting_year_end, gbd_round_id)
    validate_measure(measure_id, source)

    # Create output directory
    if out_dir:
        makedirs_safely(out_dir)

    age_group_id = standardize_all_from_raw_arg(age_group_id)
    sex_id = standardize_all_from_raw_arg(sex_id)
    location_id = resolve_all_locs(location_id,
                                   location_set_id,
                                   location_set_version_id,
                                   gbd_round_id,
                                   decomp_step)

    # handle the non-algorithmic spread of GBD reporting years
    year_id = [yr for yr in estimation_years_from_gbd_round_id(gbd_round_id)
               if (yr >= reporting_year_start) and (yr <= reporting_year_end)]

    # multiprocess getting draws and interpolating
    run_interp_helper = functools.partial(_interp_helper,
                                          gbd_id_type, gbd_id, measure_id,
                                          age_group_id, sex_id, year_id,
                                          status, version_id, decomp_step,
                                          gbd_round_id, source, downsample,
                                          interp_method)
    pool = Pool(num_workers)
    df_list = pool.map(run_interp_helper, location_id)
    pool.close()
    pool.join()
    if not all(isinstance(x, pd.DataFrame) for x in df_list):
        not_dfs = [x for x in df_list if not isinstance(x, pd.DataFrame)]
        missing_locs = [l for l in not_dfs if isinstance(l, int)]
        errors = [err for err in not_dfs if err not in missing_locs]
        if errors:
            e = "\n".join((err for err in errors))
            raise ValueError("Encountered error trying to interpolate: {}"
                             .format(e))
        else:
            df_list = [d for d in df_list if isinstance(d, pd.DataFrame)]
            if df_list:
                warnings.warn("The following locations were missing from the "
                              "draws: {}. Check the output dataframe or files "
                              "to compare against your input locations."
                              .format(missing_locs))
            else:
                raise EmptyDataFrameException(
                    "No draws were found for the source and demographics "
                    "supplied. Check that your input arguments are valid "
                    "for source='{}', gbd_id_type='{}' and gbd_id={}"
                    .format(source, gbd_id_type, gbd_id))
    df = concat(df_list)

    subset_cols = list(set([col for col in df.columns if col.endswith('_id')]))
    duplicates = df.duplicated(subset=subset_cols)
    if any(duplicates):
        raise RuntimeError("Duplicates found after subsetting columns")

    # for exposure, measure_id==None is valid because we can't pass measure_id
    # to get_draws. So lets overwrite measure_id so we can use _get_mean_values
    if not measure_id:
        measure_id = df.measure_id.unique().item()

    # run extrapolate if necessary
    if reporting_year_start == 1980:
        ages_present = df['age_group_id'].unique().tolist()
        most_detailed_ages = db_queries.get_demographics(
            'epi', gbd_round_id=gbd_round_id)['age_group_id']
        not_most_detailed = [age for age in ages_present
                             if age not in most_detailed_ages]
        if not_most_detailed:
            df = df.loc[df['age_group_id'].isin(most_detailed_ages)]
            warnings.warn("Extrapolate uses age groups to inform estimates, "
                          "and as a result cannot handle aggregate age "
                          "groups. The dataframe returned will be missing "
                          "estimates the for the following age groups "
                          "found in the draws: {}".format(not_most_detailed))

        mean_df = _get_mean_values(source, gbd_id, measure_id,
                                   most_detailed_ages, gbd_round_id,
                                   decomp_step)
        extrap_df = extrapolate(
            mean_df, df, source, gbd_id=gbd_id, gbd_id_type=gbd_id_type,
            measure_id=measure_id, location_id=location_id,
            age_group_id=age_group_id, sex_id=sex_id,
            gbd_round_id=gbd_round_id, decomp_step=decomp_step)

        if 1980 not in extrap_df['year_id'].unique().tolist():
            raise RuntimeError(
                "Error extrapolating years 1980-1989. Please submit a ticket "
                "to Central Computation."
            )
        df = concat([df, extrap_df]).reset_index(drop=True)

    # return/save data
    if out_dir:
        df.to_csv(
            os.path.join(out_dir, 'interpolated_{}.csv'.format(
                datetime.datetime.now().strftime("%Y_%m_%d_%H_%M"))),
            index=False)
        return pd.DataFrame({'out_dir': out_dir}, index=[0])
    else:
        return df